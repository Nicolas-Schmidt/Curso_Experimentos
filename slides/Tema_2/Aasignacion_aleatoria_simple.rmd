---
title: Análisis bajo asignación aleatoria
author: |
  | Diseño e implementación de experimentos en ciencias sociales
  | *Departamento de Economía (UdelaR)*
output:
  beamer_presentation:
    toc: no
    keep_tex: yes
    slide_level: 2
    includes:
      in_header: header.tex
  slidy_presentation: default
number_sections: no
theme: default
fonttheme: professionalfonts
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(knitr)
library(randomizr)

library(here)
library(tidyverse)
# library(DeclareDesign)
# library(estimatr)
library(devtools)
# library(rcompanion) ## for pairwisePermutationTest()

# library(kableExtra)

```


## Análisis bajo asignación aleatoria simple 


- *Inferencia de aleatorización (p-valores exactos para hipótesis nulas nítidas)*

\tiny 

- FEDAI, capítulo 3 
- CISSBS capítulos 5 y 6, capítulo 9 (secciones 9.3 y 9.8), capítulo 10 (sección 10.3)
- Duflo, E., Glennerster, R., & Kremer, M. (2007). Using randomization in development economics research: A toolkit. Handbook of development economics, 4, 3895-3962. (capítulos 4 y 7)
- EGAP, [10 Things to Know About Randomization Inference](https://egap.org/resource/10-things-to-know-about-hypothesis-testing/)
- Peng Ding, Avi Feller, and Luke Miratrix (2016), “Randomization Inference for Treatment Effect Variation,” Journal of the Royal Statistical Society, Series B 78: 655–671
- Samii, C., & Aronow, P. M. (2012). On equivalencies between design-based and regression-based variance estimators for randomized experiments. Statistics & Probability Letters, 82(2), 365–370.

\normalsize

- *Regresión y ajuste por covariables*

\tiny

- FEDAI, secciones 4.1, 4.2, y 4.3.
- Freedman, David A. 2008. “On Regression Adjustments in Experiments with Several Treatments.” *Annals of Applied Statistics* 2(1): 176–96.
- Lin, Winston. 2013. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” *The Annals of Applied Statistics* 7(1): 295–318.
- Wager, Stefan, Wenfei Du, Jonathan Taylor, and Robert J. Tibshirani. 2016. “High-Dimensional Regression Adjustments in Randomized Experiments.” *Proceedings of the National Academy of Sciences of the United States of America* 113(45): 12673–78.



<!-- ![](figs/lyall20093.png){#id .class width=90%} -->

# Prueba de permutación

## La señora que prueba el té \small (Fisher 1935. The Design of Experiments. Oliver and Boyd)

- ¿Tiene el té un sabor diferente según si el té se vierte en la leche o si leche se vierte en el té?
\pause

- Experimento:
  + Unidades: 8 tazas idénticas
  + Aleatorización: 4 tazas al azar en las que el té se sirve primero, otras 4 tazas primero la leche.
  + Hipótesis nula: la señora no puede notar la diferencia 
  + Estadístico: número de tazas clasificadas correctamente
  \pause

- Resultado: La señora clasificó correctamente las 8 tazas. \pause
- ¿Ha ocurrido por casualidad?


## Test de permutación 

::: {.col data-latex="{0.4\textwidth}"}

\tiny
\begin{table}[]
\begin{tabular}{cc|c|cc}
Taza  & Conjetura & Asignación & Escenarios             &       \\ 
\hline
1 & M  & \textcolor{blue}{M}  & \textcolor{black}{T}  \hfill  \textcolor{black}{T}  \hfill  \textcolor{black}{T}  &        \\
2 & T  & \textcolor{blue}{T}  & \textcolor{blue}{T}  \hfill  \textcolor{blue}{T}  \hfill  \textcolor{black}{M}  &        \\
3 & T  & \textcolor{blue}{T}  & \textcolor{blue}{T}  \hfill  \textcolor{blue}{T}  \hfill  \textcolor{blue}{T}  &        \\
4 & M  & \textcolor{blue}{M}  & \textcolor{black}{T}  \hfill  \textcolor{blue}{M}  \hfill  \textcolor{black}{T}  &  ...      \\ 
5 & M  & \textcolor{blue}{M}  & \textcolor{blue}{M}  \hfill  \textcolor{blue}{M}  \hfill  \textcolor{blue}{M}  &        \\ 
6 & T  & \textcolor{blue}{T}  & \textcolor{black}{M}  \hfill  \textcolor{black}{M}  \hfill  \textcolor{black}{M}  &        \\ 
7 & T  & \textcolor{blue}{T}  & \textcolor{black}{M}  \hfill  \textcolor{blue}{T}  \hfill  \textcolor{black}{M}  &        \\ 
8 & M  & \textcolor{blue}{M}  & \textcolor{blue}{M}  \hfill  \textcolor{blue}{M}  \hfill  \textcolor{black}{T}  &        \\  
\hline
\# correctas &    & 8          & 4 \hfill 6 \hfill 2 &         \\ 
\hline
\end{tabular}
\end{table}

:::


::: {.col data-latex="{0.3\textwidth}"}
\ 
<!-- an empty Div (with a white space), serving as
a column separator -->
:::


::: {.col data-latex="{0.25\textwidth}"}
\pause
![](figs/dis_laidy){#id .class width=100%} 


\tiny
```{r, 'ri2', echo=FALSE, include=TRUE, message=FALSE}
library(ri2)
N <- 8
declaration <- declare_ra(N = N, m = 4)
Z <- conduct_ra(declaration)
Y <- Z
dat <- data.frame(Y, Z)
ri_out <- conduct_ri(
    formula = Y ~ Z,
    declaration = declaration,
    assignment = "Z",
    sharp_hypothesis = 0,
    p = "upper",
    data = dat
  )

kable(summary(ri_out, p = "upper"))

```
:::


\pause 

- $C(N, m) = \frac{N!}{m!(N-m)!}  = \frac{8!}{4!4!} = 70$ \pause

- Bajo la hipótesis nula, la probabilidad de que la señora clasifique todas las tazas correctamente es 1/70 $=$ 0,014 \pause

- Es posible que la señora posea la capacidad de diferenciar 



## Experimentos aleatorizados (RCTs)

- ¿Por qué aleatorizar la asignación del tratamiento en los experimentos? \pause
  + Hace que los grupos de tratamiento y control sean "idénticos", aparte del tratamiento \pause
    + La distribución conjunta de cualquier covariable observada (factor de confusión) **X**  y no observado **U** previo al tratamiento es idéntica entre los dos grupos:
       $$P(\mathbf{X}, \mathbf{U} | T = 1) = P(\mathbf{X}, \mathbf{U} | T = 0)$$, \pause  donde \textbf{U} incluye los resultados potenciales $(Y(1), Y(0)$). \pause


    + Inconfundibilidad (Unconfoundedness) de la asignación al tratamiento:
        $$(X, U) \perp T, \text{y en particular},  {Y(1), Y(0)} \perp T$$ \pause


- Nos permite cuantificar formalmente el grado de incertidumbre



## Inferencia por aleatorización vs a inferencia basada en modelos


- La aleatorización como "\textcolor{brown}{base de razonamiento para la inferencia}" (Fisher)
- La aleatoriedad surge del acto físico de aleatorización, que puede utilizarse para realizar inferencias estadísticas
- También denominada *\textcolor{brown}{inferencia basada en diseño}*
- Ventaja: el diseño justifica el análisis \pause

\vspace{0.3cm}

- Contrasta con la inferencia basada en modelos, que asume una distribución de resultados potenciales
- Ventaja de la inferencia basada en el modelo: flexibilidad



## Test de hipótesis en la inferencia causal


- ¿Cómo aprender de un efecto contrafactual ($y_{Juan},T=1 \neq y_{Juan},T=0$)?

- Una solución es la **estimación de efectos causales promedios** (ATE, ITT, LATE).

- Esto es lo que llamamos el enfoque de Neyman.



## Test de hipótesis en la inferencia causal

- Otra solución es hacer **afirmaciones** o **conjeturas** sobre los efectos causales.

- Podríamos decir: "*Creo que el efecto en Juan es 5*". o "*Este experimento no tuvo ningún efecto en nadie*". Y luego preguntamos "*¿Cuánta evidencia tiene este experimento sobre esa afirmación?*"

- Esta evidencia se resume en un $p-valor$.

- A esto lo llamamos enfoque de Fisher.




## Ingredientes de una prueba de hipótesis

  - Una **hipótesis** es una afirmación sobre una relación entre resultados potenciales.

  - Una **estadístico** resume la relación entre el tratamiento y los resultados observados.

  - El **diseño** nos permite vincular la hipótesis y el estadístico: calcular un estadístico que describa una relación entre resultados potenciales.

  - El **diseño** también nos dice cómo generar una *distribución* de posibles estadísticos implícitos en la hipótesis.
 
  - Un **$p$-valor** describe la relación entre los estadísticos observadas y la distribución de posibles estadísticos hipotéticos.




# Inferencia por aleatorización 


## Inferencia por aleatorización 

- Nos permite hacer inferencias exactas, sin uso de distribuciones. \pause
- Sin depender de supuestos de normalidad, etc. \pause
- Sin depender de aproximaciones con muestras grandes. \pause
- Verdaderamente no paramétrico, pero menos flexible.



## (Sharp null) Hipótesis nula nítida de ausencia de efecto

- Hipótesis nula nítida:

$$H_0: \tau_i  = Y_i(1) - Y_i(0) = 0 \;\;\;\;  \forall i$$\pause

- Qué sucede si el tratamiento no afectara a nadie en absoluto?\pause

- Implica que no hay efecto de tratamiento **medio**, pero no hay ATE (*sharp null*)\pause

- Ejemplo sencillo con dos unidades: $\tau_1 = 1$ y $\tau_2 = -1$\pause

- Aquí, $\tau = 0$ pero se viola la hipótesis nula nítida.\pause

- Si la *sharp null* es cierta, conocemos todos los resultados potenciales:

$$Y_i(1) = Y_i(0) = Y{i}$$


## La vida bajo la Hipótesis nula nítida

![](figs/villages_po)


## La vida bajo la Hipótesis nula nítida

![](figs/villages_po2)



## p-valor

- ¿Con qué frecuencia obtendríamos un estadístico de prueba tan grande o más si se cumpliera la hipótesis nula nítida?

- $\tau^{obs} = \tau (\mathbf{D},\mathbf{Y},\mathbf{X})$

- $\Omega$ es el conjunto de $2^N$ vectores de asignación 

\pause

- **p-valor exacto**

$$Pr(\tau \geq \tau^{obs} | Y(1), Y(0), X, H_0) = \frac{1}{\Omega_0} \sum_{\mathbf{d} \in \Omega} (\tau (\mathbf{D},\mathbf{Y},\mathbf{X}) \ge \tau^{obs})$$

\pause

- Frecuencia con la que $\tau$ es mayor que el observado dividido por el número total de aleatorizaciones.



## Inferencia por aleatorización, paso a paso

1. Determinar una hipótesis nula nítida un estadístico  \pause
2. Calcular el estadístico observado: $\tau^{obs} = \tau (\mathbf{D_1},\mathbf{Y},\mathbf{X})$ \pause
3. Seleccionar aleatoriamente un vector de tratamiento diferente $\mathbf{\tilde{D}}$ tomado de $\mathbf{\Omega}$ \pause
4. Calcular $\tilde{\tau}_{1}^{obs} = \tau (\mathbf{\tilde{D}_1},\mathbf{Y},\mathbf{X})$ \pause
5. Repetir pasos 3-4 para todo el espacio de aleatorización $\Omega_0$ para obtener un vector $\tilde{\tau} = \{\tilde{\tau}_1, \dots, \tilde{\tau}_k\}$ \pause
6. Calcular el p-valor: $p= \frac{1}{k}\sum_{K=1}^{K}(\tilde{\tau}_K \geq \tau^{obs})$


## Catadora de té
```{r, 'plot', echo=TRUE}
plot(ri_out, p = "upper")
```




<!-- 
```{r echo=FALSE}
## First, create some data,
##  y0 is potential outcome to control
N <- 10
y0 <- c(0, 0, 0, 1, 1, 3, 4, 5, 190, 200)
## Different individual level treatment effects
tau <- c(10, 30, 200, 90, 10, 20, 30, 40, 90, 20)
## y1 is potential outcome to treatment
y1 <- y0 + tau
# sd(y0)
# mean(y1)-mean(y0)
# mean(tau)
## T is treatment assignment
set.seed(12345)
T <- complete_ra(N)
## Y is observed outcomes
Y <- T * y1 + (1 - T) * y0
## The data
dat <- data.frame(Y = Y, T = T, y0 = y0, tau = tau, y1 = y1)
dat$Ybin <- as.numeric(dat$Y > 100)
# dat
# pvalue(oneway_test(Y~factor(T),data=dat,distribution=exact(),alternative="less"))
# pvalue(wilcox_test(Y~factor(T),data=dat,distribution=exact(),alternative="less"))
```


```{r echo=FALSE}
## Make a bigger dataset
##  y0 is potential outcome to control
bigN <- 60
set.seed(12345)
bigdat <- data.frame(y0 = c(rep(0, 20), rnorm(20, mean = 3, sd = .5), rnorm(20, mean = 150, sd = 10)))
## Different individual level treatment effects
bigdat$tau <- c(rnorm(20, mean = 10, sd = 2), rnorm(20, mean = 20, sd = 5), rnorm(20, mean = 5, sd = 10))
## y1 is potential outcome to treatment
bigdat$y1 <- bigdat$y0 + bigdat$tau
# sd(y0)
# mean(y1)-mean(y0)
# mean(tau)
## T is treatment assignment
set.seed(12345)
bigdat$T <- complete_ra(bigN)
## Y is observed outcomes
bigdat$Y <- with(bigdat, T * y1 + (1 - T) * y0)
## The data
bigdat$Ybin <- as.numeric(bigdat$Y > quantile(bigdat$Y, .85))
```




## A hypothesis is a statement about or model of a relationship between potential outcomes

```{r}
# library(kableExtra)
knitr::kable(dat, col.names = c("Outcome", "Treatment", "$y_{i,0}$", "ITE", "$y_{i,1}$", "$Y>0$"), escape = FALSE)
```

For example, the sharp, or strong, null hypothesis of no effects is $H_0: y_{i,1} = y_{i,0}$


## Test statistics summarize treatment-to-outcome relationships

```{r, echo=TRUE}
## The mean difference test statistic
meanTT <- function(ys, z) {
  mean(ys[z == 1]) - mean(ys[z == 0])
}
## The difference of mean ranks test statistic
meanrankTT <- function(ys, z) {
  ranky <- rank(ys)
  mean(ranky[z == 1]) - mean(ranky[z == 0])
}

observedMeanTT <- meanTT(ys = Y, z = T)
observedMeanRankTT <- meanrankTT(ys = Y, z = T)
observedMeanTT
observedMeanRankTT
```

## The design links test statistic and hypothesis

What we observe for each person $i$ ($Y_i$) is either what we would have
observed in treatment ($y_{i,1}$) **or** what we would have observed in
control ($y_{i,0}$).

$$Y_i = T_i y_{i,1} + (1-T_i)* y_{i,0}$$

So, if $y_{i,1}=y_{i,0}$ then $Y_i = y_{i,0}$.

What we *actually observe* is what we *would have observed in the control condition*.

## The design guides creation of a distribution of hypothetical test statistics

We need to know how to repeat our experiment:

```{r, echo=TRUE}
repeatExperiment <- function(N) {
  complete_ra(N)
}
```

Then  we repeat it,  calculating the implied test statistic by the hypothesis and design each time:

```{r reps, echo=TRUE, cache=TRUE}
set.seed(123456)
possibleMeanDiffsH0 <- replicate(
  10000,
  meanTT(ys = Y, z = repeatExperiment(N = 10))
)
set.seed(123456)
possibleMeanRankDiffsH0 <- replicate(
  10000,
  meanrankTT(ys = Y, z = repeatExperiment(N = 10))
)
```

## Plot the randomization distributions under the null

```{r fig.cap="An example of using the design of the experiment to test a hypothesis with two different test statistics.", results='asis', echo=FALSE, fig.align='center'}
par(mfrow = c(1, 2), mgp = c(2, .5, 0), mar = c(3, 3, 0, 0), oma = c(0, 0, 3, 0))
plot(density(possibleMeanDiffsH0),
  ylim = c(0, .04),
  xlim = range(possibleMeanDiffsH0),
  lwd = 2,
  main = "", # Mean Difference Test Statistic",
  xlab = "Mean Differences Consistent with H0",
  cex.lab = 1.25, cex.axis = 1
)
rug(possibleMeanDiffsH0)
rug(observedMeanTT, lwd = 3, ticksize = .51)
text(observedMeanTT - 4, .022, "Observed Test Statistic")

plot(density(possibleMeanRankDiffsH0),
  lwd = 2,
  ylim = c(0, .45),
  xlim = c(-10, 10), # range(possibleMeanDiffsH0),
  main = "", # Mean Difference of Ranks Test Statistic",
  xlab = "Mean Difference of Ranks Consistent with H0",
  cex.lab = 1.25, cex.axis = 1
)
rug(possibleMeanRankDiffsH0)
rug(observedMeanRankTT, lwd = 3, ticksize = .9)
text(observedMeanRankTT, .45, "Observed Test Statistic")

mtext(
  side = 3, outer = TRUE, cex = 1.75,
  text = expression(paste("Distributions of Test Statistics Consistent with the Design and ", H0:y[i1] == y[i0]))
)
```

## $p$-values summarize the plots

How should we interpret these $p$-values? (Notice that they are one-tailed.)

```{r calcpvalues, echo=TRUE}
pMeanTT <- mean(possibleMeanDiffsH0 >= observedMeanTT)
pMeanRankTT <- mean(possibleMeanRankDiffsH0 >= observedMeanRankTT)
pMeanTT
pMeanRankTT
```

 -->